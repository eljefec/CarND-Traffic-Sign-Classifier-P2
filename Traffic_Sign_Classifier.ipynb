{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "## Project: Build a Traffic Sign Recognition Classifier\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "training_file = \".\\data\\\\train.p\"\n",
    "testing_file = \".\\data\\\\test.p\"\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: Dataset Summary & Exploration\n",
    "\n",
    "The pickled data is a dictionary with 4 key/value pairs:\n",
    "\n",
    "- `'features'` is a 4D array containing raw pixel data of the traffic sign images, (num examples, width, height, channels).\n",
    "- `'labels'` is a 2D array containing the label/class id of the traffic sign. The file `signnames.csv` contains id -> name mappings for each id.\n",
    "- `'sizes'` is a list containing tuples, (width, height) representing the the original width and height the image.\n",
    "- `'coords'` is a list containing tuples, (x1, y1, x2, y2) representing coordinates of a bounding box around the sign in the image. **THESE COORDINATES ASSUME THE ORIGINAL IMAGE. THE PICKLED DATA CONTAINS RESIZED VERSIONS (32 by 32) OF THESE IMAGES**\n",
    "\n",
    "Complete the basic data summary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Replace each question mark with the appropriate value.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "image_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "n_classes = np.unique(y_test).size\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)\n",
    "print(\"Label shape =\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the German Traffic Signs Dataset using the pickled file(s). This is open ended, suggestions include: plotting traffic sign images, plotting the count of each sign, etc.\n",
    "\n",
    "The [Matplotlib](http://matplotlib.org/) [examples](http://matplotlib.org/examples/index.html) and [gallery](http://matplotlib.org/gallery.html) pages are a great resource for doing visualizations in Python.\n",
    "\n",
    "**NOTE:** It's recommended you start with something simple first. If you wish to do more, come back to it after you've completed the rest of the sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Source for genfromtxt: https://carnd-forums.udacity.com/questions/18451906/answers/18451962, Author: Bharat Ramanathan.\n",
    "\n",
    "import numpy as np\n",
    "signname_bytes = np.genfromtxt('signnames.csv', delimiter=',', skip_header=1, usecols=(1,), unpack=True, dtype=None)\n",
    "\n",
    "signname_map = {}\n",
    "for i in range(len(signname_bytes)):\n",
    "    s = signname_bytes[i].tostring().decode(\"utf-8\")\n",
    "    signname_map[i] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Data exploration visualization goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Histogram of training labels.\n",
    "def plot_histogram(y, bins, titleprefix):\n",
    "    plt.hist(y, bins)\n",
    "    plt.xlabel(titleprefix + ' Label')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Histogram of ' + titleprefix + ' Labels')\n",
    "    \n",
    "plot_histogram(y_train, n_classes, 'Training')\n",
    "\n",
    "[hist, bin_edges] = np.histogram(y_train, n_classes)\n",
    "\n",
    "for i in range(len(hist)):\n",
    "    print('{}, {}, {}'.format(i, signname_map[i], hist[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Draw some training examples.\n",
    "def draw_image(image, title, fignum):\n",
    "    plt.figure(fignum)\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "\n",
    "def draw_sign(label_to_draw, fignum, desired_count):\n",
    "    count = 0    \n",
    "    for i in range(len(X_train)):\n",
    "        if y_train[i] == label_to_draw:\n",
    "            count += 1\n",
    "            draw_image(X_train[i], 'Label={},Name={},Index={}'.format(str(label_to_draw), signname_map[label_to_draw], str(i)), fignum + count)\n",
    "            if count >= desired_count:\n",
    "                return\n",
    "\n",
    "# draw_sign(2, 1, 3)\n",
    "        \n",
    "for label in range(7):\n",
    "    draw_sign(label, fignum=label, desired_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Step 2: Design and Test a Model Architecture\n",
    "\n",
    "Design and implement a deep learning model that learns to recognize traffic signs. Train and test your model on the [German Traffic Sign Dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset).\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "\n",
    "- Neural network architecture\n",
    "- Play around preprocessing techniques (normalization, rgb to grayscale, etc)\n",
    "- Number of examples per label (some have more than others).\n",
    "- Generate fake data.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). It's not required to be familiar with the approach used in the paper but, it's good practice to try to read papers like these.\n",
    "\n",
    "**NOTE:** The LeNet-5 implementation shown in the [classroom](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/601ae704-1035-4287-8b11-e2c2716217ad/concepts/d4aca031-508f-4e0b-b493-e7b706120f81) at the end of the CNN lesson is a solid starting point. You'll have to change the number of classes and possibly the preprocessing, but aside from that it's plug and play!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Preprocess the data here.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "\n",
    "_Describe how you preprocessed the data. Why did you choose that technique?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "I normalized the image data with Min-Max scaling to a range of [0.1, 0.9].\n",
    "\n",
    "I wanted to let the neural network learn whatever processing was appropriate for classifying the images. I considered performing YUV-conversion and Y-channel global and local contrast normalization as described in [1], but I decided to simply add a color-space transformation layer as described in [2]. This let the neural network figure out the best color-space transformation for this classification problem.\n",
    "\n",
    "[1] Pierre Sermanet and Yann LeCun, Traffic Sign Recognition with Multi-Scale Convolutional Networks, URL: http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf. Retrieved 1/19/2017.\n",
    "\n",
    "[2] Alexandros Karargyris, Color Space Transformation Network, URL: https://arxiv.org/ftp/arxiv/papers/1511/1511.01064.pdf. Retrieved 1/19/2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Author: Vivek Yadav\n",
    "### https://github.com/vxy10/ImageAugmentation\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def augment_brightness_camera_images(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = .25+np.random.uniform()\n",
    "    #print(random_bright)\n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "\n",
    "def transform_image(img,ang_range,shear_range,trans_range,brightness=0):\n",
    "    '''\n",
    "    This function transforms images to generate new images.\n",
    "    The function takes in following arguments,\n",
    "    1- Image\n",
    "    2- ang_range: Range of angles for rotation\n",
    "    3- shear_range: Range of values to apply affine transform to\n",
    "    4- trans_range: Range of values to apply translations over.\n",
    "\n",
    "    A Random uniform distribution is used to generate different parameters for transformation\n",
    "\n",
    "    '''\n",
    "    # Rotation\n",
    "    ang_rot = np.random.uniform(ang_range)-ang_range/2\n",
    "    rows,cols,ch = img.shape    \n",
    "    Rot_M = cv2.getRotationMatrix2D((cols/2,rows/2),ang_rot,1)\n",
    "\n",
    "    # Translation\n",
    "    tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    tr_y = trans_range*np.random.uniform()-trans_range/2\n",
    "    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "\n",
    "    # Shear\n",
    "    pts1 = np.float32([[5,5],[20,5],[5,20]])\n",
    "\n",
    "    pt1 = 5+shear_range*np.random.uniform()-shear_range/2\n",
    "    pt2 = 20+shear_range*np.random.uniform()-shear_range/2\n",
    "\n",
    "    pts2 = np.float32([[pt1,5],[pt2,pt1],[5,pt2]])\n",
    "\n",
    "    shear_M = cv2.getAffineTransform(pts1,pts2)\n",
    "\n",
    "    img = cv2.warpAffine(img,Rot_M,(cols,rows))\n",
    "    img = cv2.warpAffine(img,Trans_M,(cols,rows))\n",
    "    img = cv2.warpAffine(img,shear_M,(cols,rows))\n",
    "\n",
    "    # Brightness\n",
    "    if brightness == 1:\n",
    "        img = augment_brightness_camera_images(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutate_image(image):\n",
    "    return transform_image(image, 10, 4, 2, brightness=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[hist, bin_edges] = np.histogram(y_train, n_classes)\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split training data into training and validation sets.\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Generate additional data.\n",
    "\n",
    "import random\n",
    "\n",
    "def generate_extra_data(X, y, extra):\n",
    "    total_train_size = X.shape[0] * (1 + extra)\n",
    "\n",
    "    JX = np.zeros([total_train_size, X.shape[1], X.shape[2], X.shape[3]], np.uint8)\n",
    "    Jy = np.zeros([total_train_size], np.uint8)\n",
    "\n",
    "    J_index = 0\n",
    "    total_generated = 0\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        curx = X[i]\n",
    "        cury = y[i]\n",
    "        \n",
    "        base = (extra + 1) * i\n",
    "        JX[base] = curx\n",
    "        Jy[base] = cury\n",
    "        \n",
    "        for x in range(extra):\n",
    "            offset = x + 1\n",
    "            JX[base + offset] = mutate_image(curx)\n",
    "            Jy[base + offset] = cury\n",
    "            total_generated += 1\n",
    "\n",
    "    print('Done generating. total_generated=', total_generated)\n",
    "    \n",
    "    return [JX, Jy]\n",
    "\n",
    "def generate_extra_data_min(X, y, min_train_size):\n",
    "    total_train_size = 0\n",
    "\n",
    "    [hist, bin_edges] = np.histogram(y, n_classes)\n",
    "\n",
    "    for count in hist:\n",
    "        if (count > min_train_size):\n",
    "            total_train_size += count\n",
    "        else:\n",
    "            total_train_size += min_train_size\n",
    "\n",
    "    JX = np.zeros([total_train_size, X.shape[1], X.shape[2], X.shape[3]], np.uint8)\n",
    "    Jy = np.zeros([total_train_size], np.uint8)\n",
    "\n",
    "    J_index = 0\n",
    "    total_generated = 0\n",
    "    for label in range(n_classes):\n",
    "        label_examples = np.where(y == label)[0]\n",
    "\n",
    "        # Copy over existing training examples.\n",
    "        for i in range(label_examples.size):\n",
    "            JX[J_index] = X[label_examples[i]]\n",
    "            Jy[J_index] = y[label_examples[i]]\n",
    "            J_index += 1\n",
    "\n",
    "        # Generate mutated examples if needed.\n",
    "        if label_examples.size < min_train_size:\n",
    "            generate_count = min_train_size - label_examples.size\n",
    "\n",
    "            for i in range(generate_count):\n",
    "                chosen = label_examples[random.randrange(label_examples.size)]\n",
    "                JX[J_index] = mutate_image(X[chosen])\n",
    "                Jy[J_index] = label\n",
    "                J_index += 1\n",
    "\n",
    "            total_generated += generate_count\n",
    "\n",
    "    print('Done generating. total_generated=', total_generated)\n",
    "    \n",
    "    return [JX, Jy]\n",
    "    \n",
    "[JX_train, Jy_train] = generate_extra_data(X_train, y_train, 10)\n",
    "#[JX_train, Jy_train] = generate_extra_data_min(X_train, y_train, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.sum(JX_train[0]-JX_train[4]))\n",
    "\n",
    "# Examine generated data.\n",
    "#for i in range(10):\n",
    "#    draw_image(JX_train[i], 'blah', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "_Describe how you set up the training, validation and testing data for your model. **Optional**: If you generated additional data, how did you generate the data? Why did you generate the data? What are the differences in the new dataset (with generated data) from the original dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "#### Splitting Training, Validation, and Testing Data\n",
    "I set aside the test data (X_test, y_test) and did not touch it during my model development and neural-network tweaking.\n",
    "\n",
    "I split the training data (X_train, y_train) into 2 sets: training' and validation data (X_train, y_train) and (X_validation, y_validation). 10% of the original training data was randomly selected and separated as the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_histogram(y_train, n_classes, 'Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer (continued):\n",
    "#### Generating Additional Data\n",
    "A histogram of the training labels shows a non-uniform distribution (see the above cell). Some of the classes have as few as 200 examples. To give my model plenty of data to learn from and to make it more robust against pictures of traffic signs at angles and with poor lighting, I generated additional data.\n",
    "\n",
    "I generated additional data using a helper function \"transform_image\" written by Vivek Yadav found at [3]. It generates a new image using OpenCV to rotate, shear, translate, and augment the brightness of an existing image. I found that too much jitter reduced my validation accuracy. This was probably because excessive jitter results in training data that are so different from the original data that they mislead the model. I experimented with different ranges of rotation, shear, and translation until validation accuracy was actually better than without the additional data.\n",
    "\n",
    "I tried two approaches: \n",
    "1. Scale up the count of training examples by some factor, thereby keeping the above non-uniform distribution.\n",
    "2. Increase the count of training examples to cause a uniform distribution of classes.\n",
    "\n",
    "The first approach resulted in a better validation accuracy.\n",
    "\n",
    "[3] Vivek Yadav, Image Augmentation, URL: https://github.com/vxy10/ImageAugmentation, Retrieved: 1/20/2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use jittered training data as training data.\n",
    "[X_train, y_train] = [JX_train, Jy_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "MAX_EPOCHS = 200\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def conv_activation(x, filter_height, filter_width, in_depth, out_depth, mean, stddev):\n",
    "    h = (tf.nn.conv2d(x, \n",
    "                      tf.Variable(tf.truncated_normal([filter_height, filter_width, in_depth, out_depth], mean = mean, stddev = stddev)), \n",
    "                      [1, 1, 1, 1], \n",
    "                      'VALID') \n",
    "              + tf.Variable(tf.zeros(out_depth)))\n",
    "    \n",
    "    # Activation.\n",
    "    return tf.nn.relu(h)\n",
    "\n",
    "def conv5x5_activation(x, in_depth, out_depth, mean, stddev):\n",
    "    return conv_activation(x, 5, 5, in_depth, out_depth, mean, stddev)\n",
    "\n",
    "def conv3x3_activation(x, in_depth, out_depth, mean, stddev):\n",
    "    return conv_activation(x, 3, 3, in_depth, out_depth, mean, stddev)\n",
    "    \n",
    "def maxpool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "def dropout(x, keep_prob):\n",
    "    return tf.nn.dropout(x, keep_prob)\n",
    "\n",
    "def fully_connected(x, in_count, out_count, mean, stddev):\n",
    "    return (tf.matmul(x, \n",
    "                      tf.Variable(tf.truncated_normal((in_count, out_count), mean = mean, stddev = stddev)))\n",
    "            + tf.Variable(tf.zeros(out_count)))\n",
    "\n",
    "def make_branch(h, depth, mean, stddev, keep_prob):\n",
    "    # Layer 1: Convolutional. Input = 32x32x3. Output = 28x28xdepth.\n",
    "    h = conv5x5_activation(h, 3, depth, mean, stddev)\n",
    "    \n",
    "    # Convolutional. Output = 24x24x(depth*1.5).\n",
    "    h = conv5x5_activation(h, depth, int(depth * 3 / 2), mean, stddev)\n",
    "    \n",
    "    # Convolutional. Output = 20x20x(depth*2).\n",
    "    h = conv5x5_activation(h, int(depth * 3 / 2), depth * 2, mean, stddev)\n",
    "\n",
    "    # Output = 10x10x(depth*2)\n",
    "    h = maxpool(h)\n",
    "    \n",
    "    # Convolutional. Output = 8x8x(depth*2.5).\n",
    "    h = conv3x3_activation(h, depth * 2, int(depth * 5 / 2), mean, stddev)\n",
    "\n",
    "    # Pooling.\n",
    "    h = dropout(h, keep_prob)\n",
    "    \n",
    "    return h\n",
    "\n",
    "def define_nn_architecture(x, keep_prob):    \n",
    "    # Hyperparameters\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # Let this layer modify color. Input = 32x32x3. Ouput = 32x32x3. \n",
    "    # This layer is inspired by \"Color Space Transformation Network\" at https://arxiv.org/ftp/arxiv/papers/1511/1511.01064.pdf.\n",
    "    h = conv_activation(x, 1, 1, 3, 3, mu, sigma)\n",
    "    \n",
    "    # This branch-then-merge architecture is inspired by Vivek Yadav's post.\n",
    "    # https://chatbotslife.com/german-sign-classification-using-deep-learning-neural-networks-98-8-solution-d05656bf51ad\n",
    "    b1 = make_branch(h, 32, mu, sigma, keep_prob)\n",
    "    b2 = make_branch(h, 64, mu, sigma, keep_prob)\n",
    "    b3 = make_branch(h, 128, mu, sigma, keep_prob)\n",
    "    \n",
    "    # Merge branches. Output = 10x10x112.\n",
    "    h = tf.concat_v2([b1, b2, b3], axis=3)\n",
    "    \n",
    "    # Flatten. Output = concat_dim.\n",
    "    h = flatten(h)\n",
    "    \n",
    "    concat_dim = h.get_shape().dims[1].value\n",
    "    \n",
    "    print('concat_dim= ', concat_dim)\n",
    "    \n",
    "    # Output = 400.\n",
    "    h = fully_connected(h, concat_dim, 800, mu, sigma)\n",
    "    \n",
    "    # Activation.\n",
    "    h = dropout(h, keep_prob)\n",
    "\n",
    "    # Output = 120.\n",
    "    h = fully_connected(h, 800, 400, mu, sigma)\n",
    "    \n",
    "    # Activation.\n",
    "    h = dropout(h, keep_prob)\n",
    "\n",
    "    # Output = n_classes.\n",
    "    h = fully_connected(h, 400, n_classes, mu, sigma)\n",
    "    \n",
    "    h = dropout(h, keep_prob)\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)  For reference on how to build a deep neural network using TensorFlow, see [Deep Neural Network in TensorFlow\n",
    "](https://classroom.udacity.com/nanodegrees/nd013/parts/fbf77062-5703-404e-b60c-95b78b2f3f9e/modules/6df7ae49-c61c-4bb2-a23e-6527e69209ec/lessons/b516a270-8600-4f93-a0a3-20dfeabe5da6/concepts/83a3a2a2-a9bd-4b7b-95b0-eb924ab14432) from the classroom._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "My final architecture is a convolutional neural network. I augmented the LeNet architecture with more layers, deeper convolutional layers, and wider fully connected layers. Inspired by Vivek Yadav's post [4], I added a branch-then-merge section at the start. Each branch is a series of convolutional layers, a maxpool, and a dropout layer. Each branch has a different convolutional filter depth.\n",
    "\n",
    "[4] Vivek Yadav, (98.8% solution) German sign classification using deep learning neural networks, URL:  https://chatbotslife.com/german-sign-classification-using-deep-learning-neural-networks-98-8-solution-d05656bf51ad. Retrieved 1/27/2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "### One-hot encode labels.\n",
    "\n",
    "def safe_one_hot(y, num_labels):\n",
    "    # From https://github.com/tensorflow/tensorflow/issues/6509\n",
    "    sparse_labels = tf.reshape(y, [-1, 1])\n",
    "    derived_size = tf.shape(sparse_labels)[0]\n",
    "    indices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])\n",
    "    concated = tf.concat(1, [indices, sparse_labels])\n",
    "    outshape = tf.concat(0, [tf.reshape(derived_size, [1]), tf.reshape(num_labels, [1])])\n",
    "    one_hot_y = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)\n",
    "    return one_hot_y\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "# one_hot_y = tf.one_hot(y, n_classes)\n",
    "one_hot_y = safe_one_hot(y, n_classes)\n",
    "\n",
    "### Calculate logits, cross-entropy, loss, and setup optimizer.\n",
    "\n",
    "rate = 0.0001\n",
    "\n",
    "kp = tf.placeholder(tf.float32)\n",
    "\n",
    "logits = define_nn_architecture(x, kp)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Evaluate accuracy.\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, kp: 1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def format_seconds(secs):\n",
    "    delta = datetime.timedelta(seconds=int(secs))\n",
    "    return str(delta)\n",
    "\n",
    "def format_now():\n",
    "    return datetime.datetime.now().strftime('%Y-%m-%d_%Hh%Mm%S')\n",
    "\n",
    "import time\n",
    "start = time.monotonic()\n",
    "end = time.monotonic()\n",
    "print(format_seconds(end - start))\n",
    "print(format_now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Stopwatch:\n",
    "    def __init__(self, autostart = True):\n",
    "        self._duration = 0\n",
    "        self._started = False\n",
    "        self._start = 0\n",
    "        if (autostart):\n",
    "            self.start()\n",
    "        \n",
    "    def start(self):\n",
    "        if not self._started:\n",
    "            self._started = True\n",
    "            self._start = time.monotonic()\n",
    "        return self\n",
    "    \n",
    "    def stop(self):\n",
    "        if not self._started:\n",
    "            raise RuntimeError('Cannot stop stopwatch that has not been started.')\n",
    "        end = time.monotonic()\n",
    "        self._duration += (end - self._start)\n",
    "        self._started = False\n",
    "        self._start = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self._duration = 0\n",
    "        self._started = False\n",
    "        self._start = 0\n",
    "        \n",
    "    def format_duration(self):\n",
    "        return format_seconds(self._duration)\n",
    "    \n",
    "sw = Stopwatch().start()\n",
    "sw.stop()\n",
    "print(sw.format_duration())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(image_data):\n",
    "    \"\"\"\n",
    "    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "    :param image_data: The image data to be normalized\n",
    "    :return: Normalized image data\n",
    "    \"\"\"\n",
    "    a = 0.1\n",
    "    b = 0.9\n",
    "    rgb_min = 0\n",
    "    rgb_max = 255\n",
    "    return a + ( ( (image_data - rgb_min)*(b - a) )/( rgb_max - rgb_min ) )\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_validation = normalize(X_validation)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(sess, X_pred):\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    output = sess.run(softmax, feed_dict={x: X_pred, kp: 1.0})\n",
    "    predictions = np.argmax(output, axis = 1)\n",
    "    return predictions\n",
    "\n",
    "test_files = ['bend_right.png',\n",
    "              'do_not_enter.png',\n",
    "              'german_do_not_enter.png',\n",
    "              'german_priority.png',\n",
    "              'keep_right.png',\n",
    "              'no_passing.png',\n",
    "              'speed_limit.png',\n",
    "              'stop_sign.png',\n",
    "              'uk_speed_limit_50.png',\n",
    "              'yield.png']\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def read_test_images():\n",
    "    X = []\n",
    "    for file in test_files:\n",
    "        img = mpimg.imread('.\\\\test_images\\\\' + file)\n",
    "        X.append(img)\n",
    "    X = np.array(X)\n",
    "    return normalize(X)\n",
    "    \n",
    "def predict_test_images(sess):\n",
    "    X = read_test_images()\n",
    "    predictions = predict(sess, X)\n",
    "    \n",
    "    for i in range(len(test_files)):\n",
    "        id_pred = predictions[i]\n",
    "        print('{}: Prediction: {}, Name: {}'.format(test_files[i], id_pred, signname_map[id_pred]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Measure accuracy of model with test set.\n",
    "\n",
    "def evaluate_test_accuracy(sess):\n",
    "    test_stopwatch = Stopwatch()\n",
    "    \n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    \n",
    "    test_stopwatch.stop()\n",
    "\n",
    "    print(\"Test Set Size: \", len(y_test))\n",
    "    print(\"Test Accuracy: {:.4f}\".format(test_accuracy))\n",
    "    print(\"Duration: {}\".format(test_stopwatch.format_duration()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Train model.\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "\n",
    "train_model = True\n",
    "epochs_since_improvement_limit = 2\n",
    "min_accuracy = 0.99\n",
    "keep_prob_during_training = 0.4\n",
    "\n",
    "if (train_model):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        num_examples = len(X_train)\n",
    "\n",
    "        best_validation_accuracy = 0.0\n",
    "        best_train_accuracy = 0.0\n",
    "\n",
    "        print(\"Training... num_examples: \", num_examples)\n",
    "        print()\n",
    "        print(\"EPOCH, ValAcc, TrainSubsetAcc, Duration\")\n",
    "        print()\n",
    "\n",
    "        train_stopwatch = Stopwatch()\n",
    "\n",
    "        for i in range(MAX_EPOCHS):\n",
    "            epoch_stopwatch = Stopwatch()\n",
    "\n",
    "            X_train, y_train = shuffle(X_train, y_train)\n",
    "            for offset in range(0, num_examples, BATCH_SIZE):\n",
    "                end = offset + BATCH_SIZE\n",
    "                batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "                sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, kp: keep_prob_during_training})\n",
    "\n",
    "            validation_accuracy = evaluate(X_validation, y_validation)\n",
    "\n",
    "            val_size = len(y_validation)\n",
    "            train_accuracy = evaluate(X_train[:val_size], y_train[:val_size])\n",
    "            \n",
    "            if validation_accuracy > best_validation_accuracy:\n",
    "                best_validation_accuracy = validation_accuracy\n",
    "                epochs_since_improvement = 0\n",
    "            #elif train_accuracy > best_train_accuracy:\n",
    "                #best_train_accuracy = train_accuracy\n",
    "                #epochs_since_improvement = 0\n",
    "            else:\n",
    "                epochs_since_improvement += 1            \n",
    "\n",
    "            epoch_stopwatch.stop()\n",
    "\n",
    "            print(\"{}, {:.3f}, {:.3f}, {}\".format(i+1, validation_accuracy, train_accuracy, epoch_stopwatch.format_duration()))\n",
    "            print()\n",
    "\n",
    "            if (epochs_since_improvement >= epochs_since_improvement_limit \n",
    "                and best_validation_accuracy >= min_accuracy):\n",
    "                #and best_train_accuracy >= min_accuracy):\n",
    "                print(\"Stopping early. Validation accuracy has not improved in {} epochs.\".format(epochs_since_improvement_limit))\n",
    "                print()\n",
    "                break\n",
    "\n",
    "        train_stopwatch.stop()\n",
    "\n",
    "        print(\"Training Duration: \", train_stopwatch.format_duration())\n",
    "        print()    \n",
    "        print(\"Best Validation Accuracy: \", best_validation_accuracy)\n",
    "        print()\n",
    "\n",
    "        model_filename = '.\\\\cnn_branch_pyramid_{:.1f}_{}'.format(best_validation_accuracy * 100, format_now())\n",
    "        saver.save(sess, model_filename)\n",
    "        print(\"Model saved: \", model_filename)\n",
    "        \n",
    "        evaluate_test_accuracy(sess)\n",
    "        predict_test_images(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 conv layers in 3 branches, dropouts between fully connected layers, learning rate=0.0001, 10 examples per example, keep_prob=0.4\n",
    "\n",
    "Training... num_examples:  388168\n",
    "\n",
    "EPOCH, ValAcc, TrainSubsetAcc, Duration\n",
    "\n",
    "1, 0.455, 0.397, 0:06:46\n",
    "\n",
    "2, 0.559, 0.512, 0:06:43\n",
    "\n",
    "3, 0.737, 0.654, 0:06:39\n",
    "\n",
    "4, 0.885, 0.812, 0:06:39\n",
    "\n",
    "5, 0.946, 0.886, 0:06:39\n",
    "\n",
    "6, 0.966, 0.936, 0:06:40\n",
    "\n",
    "7, 0.983, 0.952, 0:06:46\n",
    "\n",
    "8, 0.990, 0.956, 0:06:44\n",
    "\n",
    "9, 0.993, 0.973, 0:06:44\n",
    "\n",
    "10, 0.995, 0.979, 0:06:45\n",
    "\n",
    "11, 0.996, 0.984, 0:06:39\n",
    "\n",
    "12, 0.996, 0.979, 0:06:38\n",
    "\n",
    "13, 0.997, 0.989, 0:06:43\n",
    "\n",
    "14, 0.996, 0.987, 0:06:43\n",
    "\n",
    "15, 0.998, 0.988, 0:06:42\n",
    "\n",
    "16, 0.998, 0.992, 0:06:44\n",
    "\n",
    "17, 0.997, 0.993, 0:06:41\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 2 epochs.\n",
    "\n",
    "Training Duration:  1:54:03\n",
    "\n",
    "Best Validation Accuracy:  0.997704667177\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_99.8_2017-01-26_16h58m44\n",
    "Test Set Size:  12630\n",
    "Test Accuracy: 0.9827\n",
    "Duration: 0:00:04\n",
    "bend_right.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "do_not_enter.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "german_do_not_enter.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "german_priority.png: Prediction: 10, Name: No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "keep_right.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "no_passing.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "speed_limit.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "stop_sign.png: Prediction: 8, Name: Speed limit (120km/h)\n",
    "\n",
    "uk_speed_limit_50.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "yield.png: Prediction: 5, Name: Speed limit (80km/h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 conv layers in 3 branches, dropouts between fully connected layers, learning rate=0.0001, 10000 min examples per class, keep_prob=0.4\n",
    "\n",
    "Training... num_examples:  430000\n",
    "\n",
    "EPOCH, ValAcc, TrainSubsetAcc, Duration\n",
    "\n",
    "1, 0.309, 0.214, 0:07:22\n",
    "\n",
    "2, 0.541, 0.431, 0:07:19\n",
    "\n",
    "3, 0.776, 0.700, 0:07:18\n",
    "\n",
    "4, 0.882, 0.815, 0:07:18\n",
    "\n",
    "5, 0.945, 0.893, 0:07:18\n",
    "\n",
    "6, 0.961, 0.938, 0:07:18\n",
    "\n",
    "7, 0.973, 0.957, 0:07:25\n",
    "\n",
    "8, 0.981, 0.967, 0:07:25\n",
    "\n",
    "9, 0.986, 0.972, 0:07:27\n",
    "\n",
    "10, 0.990, 0.977, 0:07:29\n",
    "\n",
    "11, 0.991, 0.980, 0:07:30\n",
    "\n",
    "12, 0.993, 0.983, 0:07:24\n",
    "\n",
    "13, 0.994, 0.982, 0:07:29\n",
    "\n",
    "14, 0.995, 0.986, 0:07:31\n",
    "\n",
    "15, 0.996, 0.990, 0:07:30\n",
    "\n",
    "16, 0.995, 0.989, 0:07:28\n",
    "\n",
    "17, 0.995, 0.990, 0:07:26\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 2 epochs.\n",
    "\n",
    "Training Duration:  2:06:04\n",
    "\n",
    "Best Validation Accuracy:  0.995919408314\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_99.6_2017-01-26_14h53m51\n",
    "Test Set Size:  12630\n",
    "Test Accuracy: 0.9805\n",
    "Duration: 0:00:04\n",
    "bend_right.png: Prediction: 18, Name: General caution\n",
    "\n",
    "do_not_enter.png: Prediction: 18, Name: General caution\n",
    "\n",
    "german_do_not_enter.png: Prediction: 18, Name: General caution\n",
    "\n",
    "german_priority.png: Prediction: 18, Name: General caution\n",
    "\n",
    "keep_right.png: Prediction: 18, Name: General caution\n",
    "\n",
    "no_passing.png: Prediction: 18, Name: General caution\n",
    "\n",
    "speed_limit.png: Prediction: 18, Name: General caution\n",
    "\n",
    "stop_sign.png: Prediction: 18, Name: General caution\n",
    "\n",
    "uk_speed_limit_50.png: Prediction: 18, Name: General caution\n",
    "\n",
    "yield.png: Prediction: 18, Name: General caution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 conv layers in 3 branches, dropouts between fully connected layers, learning rate=0.0001, 5000 min examples per class, keep_prob=0.5\n",
    "\n",
    "EPOCH, ValAcc, TrainSubsetAcc, Duration\n",
    "\n",
    "1, 0.640, 0.493, 0:03:47\n",
    "\n",
    "2, 0.824, 0.710, 0:03:48\n",
    "\n",
    "3, 0.920, 0.834, 0:03:48\n",
    "\n",
    "4, 0.956, 0.893, 0:03:48\n",
    "\n",
    "5, 0.966, 0.923, 0:03:48\n",
    "\n",
    "6, 0.983, 0.955, 0:03:48\n",
    "\n",
    "7, 0.986, 0.965, 0:03:48\n",
    "\n",
    "8, 0.989, 0.973, 0:03:48\n",
    "\n",
    "9, 0.992, 0.982, 0:03:48\n",
    "\n",
    "10, 0.992, 0.980, 0:03:48\n",
    "\n",
    "11, 0.994, 0.984, 0:03:48\n",
    "\n",
    "12, 0.994, 0.988, 0:03:48\n",
    "\n",
    "13, 0.994, 0.992, 0:03:48\n",
    "\n",
    "14, 0.996, 0.993, 0:03:48\n",
    "\n",
    "15, 0.996, 0.992, 0:03:48\n",
    "\n",
    "16, 0.996, 0.991, 0:03:48\n",
    "\n",
    "17, 0.996, 0.993, 0:03:48\n",
    "\n",
    "18, 0.997, 0.995, 0:03:48\n",
    "\n",
    "19, 0.997, 0.995, 0:03:47\n",
    "\n",
    "20, 0.997, 0.995, 0:03:48\n",
    "\n",
    "21, 0.997, 0.993, 0:03:47\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 2 epochs.\n",
    "\n",
    "Training Duration:  1:19:53\n",
    "\n",
    "Best Validation Accuracy:  0.997194593216\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_99.7_2017-01-26_02h35m23\n",
    "bend_right.png: Prediction: 12, Name: Priority road\n",
    "\n",
    "do_not_enter.png: Prediction: 12, Name: Priority road\n",
    "\n",
    "german_do_not_enter.png: Prediction: 12, Name: Priority road\n",
    "\n",
    "german_priority.png: Prediction: 12, Name: Priority road\n",
    "\n",
    "keep_right.png: Prediction: 12, Name: Priority road\n",
    "\n",
    "no_passing.png: Prediction: 12, Name: Priority road\n",
    "\n",
    "speed_limit.png: Prediction: 12, Name: Priority road\n",
    "\n",
    "stop_sign.png: Prediction: 12, Name: Priority road\n",
    "\n",
    "uk_speed_limit_50.png: Prediction: 12, Name: Priority road\n",
    "\n",
    "yield.png: Prediction: 12, Name: Priority road"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 conv layers in 3 branches, dropouts between fully connected layers\n",
    "\n",
    "Training... num_examples:  215000\n",
    "\n",
    "EPOCH, ValAcc, TrainSubsetAcc, Duration\n",
    "\n",
    "1, 0.946, 0.878, 0:03:52\n",
    "\n",
    "2, 0.988, 0.957, 0:03:49\n",
    "\n",
    "3, 0.990, 0.975, 0:03:48\n",
    "\n",
    "4, 0.988, 0.983, 0:03:49\n",
    "\n",
    "5, 0.994, 0.984, 0:03:48\n",
    "\n",
    "6, 0.995, 0.981, 0:03:48\n",
    "\n",
    "7, 0.992, 0.986, 0:03:49\n",
    "\n",
    "8, 0.993, 0.987, 0:03:48\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 2 epochs.\n",
    "\n",
    "Training Duration:  0:30:34\n",
    "\n",
    "Best Validation Accuracy:  0.994899260393\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_99.5_2017-01-26_00h57m57\n",
    "bend_right.png: Prediction: 13, Name: Yield\n",
    "\n",
    "do_not_enter.png: Prediction: 13, Name: Yield\n",
    "\n",
    "german_do_not_enter.png: Prediction: 15, Name: No vehicles\n",
    "\n",
    "german_priority.png: Prediction: 13, Name: Yield\n",
    "\n",
    "keep_right.png: Prediction: 13, Name: Yield\n",
    "\n",
    "no_passing.png: Prediction: 13, Name: Yield\n",
    "\n",
    "speed_limit.png: Prediction: 13, Name: Yield\n",
    "\n",
    "stop_sign.png: Prediction: 13, Name: Yield\n",
    "\n",
    "uk_speed_limit_50.png: Prediction: 29, Name: Bicycles crossing\n",
    "\n",
    "yield.png: Prediction: 13, Name: Yield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proper dropout, 3 conv layers in 3 branches, normalization\n",
    "\n",
    "Training... num_examples:  215000\n",
    "\n",
    "EPOCH, ValAcc, TrainSubsetAcc, Duration\n",
    "\n",
    "1, 0.993, 0.971, 0:01:52\n",
    "\n",
    "2, 0.993, 0.988, 0:01:50\n",
    "\n",
    "3, 0.993, 0.992, 0:01:50\n",
    "\n",
    "4, 0.994, 0.993, 0:01:50\n",
    "\n",
    "5, 0.995, 0.995, 0:01:50\n",
    "\n",
    "6, 0.996, 0.996, 0:01:50\n",
    "\n",
    "7, 0.997, 0.998, 0:01:50\n",
    "\n",
    "8, 0.996, 0.995, 0:01:49\n",
    "\n",
    "9, 0.996, 0.998, 0:01:49\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 2 epochs.\n",
    "\n",
    "Training Duration:  0:16:35\n",
    "\n",
    "Best Validation Accuracy:  0.996684519255\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_99.7_2017-01-25_23h20m01\n",
    "bend_right.png: Prediction: 3, Name: Speed limit (60km/h)\n",
    "\n",
    "do_not_enter.png: Prediction: 3, Name: Speed limit (60km/h)\n",
    "\n",
    "german_do_not_enter.png: Prediction: 3, Name: Speed limit (60km/h)\n",
    "\n",
    "german_priority.png: Prediction: 3, Name: Speed limit (60km/h)\n",
    "\n",
    "keep_right.png: Prediction: 3, Name: Speed limit (60km/h)\n",
    "\n",
    "no_passing.png: Prediction: 3, Name: Speed limit (60km/h)\n",
    "\n",
    "speed_limit.png: Prediction: 3, Name: Speed limit (60km/h)\n",
    "\n",
    "stop_sign.png: Prediction: 3, Name: Speed limit (60km/h)\n",
    "\n",
    "uk_speed_limit_50.png: Prediction: 3, Name: Speed limit (60km/h)\n",
    "\n",
    "yield.png: Prediction: 3, Name: Speed limit (60km/h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proper dropout, dropout at end of each branch, 2 conv layers in 3 branches, 1 deeply-layered branch, min_accuracy=0.995\n",
    "\n",
    "Training... num_examples:  211728\n",
    "\n",
    "EPOCH, ValAcc, TrainSubsetAcc, Duration\n",
    "\n",
    "1, 0.907, 0.850, 0:02:10\n",
    "\n",
    "2, 0.962, 0.936, 0:02:09\n",
    "\n",
    "3, 0.975, 0.952, 0:02:08\n",
    "\n",
    "4, 0.986, 0.964, 0:02:08\n",
    "\n",
    "5, 0.992, 0.975, 0:02:08\n",
    "\n",
    "6, 0.994, 0.981, 0:02:08\n",
    "\n",
    "7, 0.995, 0.982, 0:02:08\n",
    "\n",
    "8, 0.775, 0.710, 0:02:08\n",
    "\n",
    "9, 0.932, 0.888, 0:02:08\n",
    "\n",
    "10, 0.975, 0.955, 0:02:07\n",
    "\n",
    "11, 0.993, 0.980, 0:02:07\n",
    "\n",
    "12, 0.995, 0.986, 0:02:08\n",
    "\n",
    "13, 0.995, 0.994, 0:02:07\n",
    "\n",
    "14, 0.995, 0.989, 0:02:07\n",
    "\n",
    "15, 0.995, 0.993, 0:02:08\n",
    "\n",
    "16, 0.996, 0.996, 0:02:08\n",
    "\n",
    "17, 0.998, 0.996, 0:02:08\n",
    "\n",
    "18, 0.997, 0.996, 0:02:08\n",
    "\n",
    "19, 0.997, 0.996, 0:02:09\n",
    "\n",
    "20, 0.997, 0.998, 0:02:08\n",
    "\n",
    "21, 0.997, 1.000, 0:02:09\n",
    "\n",
    "22, 0.996, 0.996, 0:02:09\n",
    "\n",
    "23, 0.998, 0.997, 0:02:09\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 2 epochs.\n",
    "\n",
    "Training Duration:  0:49:19\n",
    "\n",
    "Best Validation Accuracy:  0.998214741137\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_99.8_2017-01-25_18h31m54\n",
    "bend_right.png: Prediction: 34, Name: Turn left ahead\n",
    "\n",
    "do_not_enter.png: Prediction: 38, Name: Keep right\n",
    "\n",
    "german_do_not_enter.png: Prediction: 2, Name: Speed limit (50km/h)\n",
    "\n",
    "german_priority.png: Prediction: 38, Name: Keep right\n",
    "\n",
    "keep_right.png: Prediction: 34, Name: Turn left ahead\n",
    "\n",
    "no_passing.png: Prediction: 21, Name: Double curve\n",
    "\n",
    "speed_limit.png: Prediction: 38, Name: Keep right\n",
    "\n",
    "stop_sign.png: Prediction: 2, Name: Speed limit (50km/h)\n",
    "\n",
    "uk_speed_limit_50.png: Prediction: 34, Name: Turn left ahead\n",
    "\n",
    "yield.png: Prediction: 38, Name: Keep right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout at end of each branch, 3 conv layers in each branch, wider fully-connected layers, min_accuracy=0.99\n",
    "\n",
    "38, 0.997, 0.991, 0:01:21\n",
    "\n",
    "39, 0.992, 0.985, 0:01:21\n",
    "\n",
    "40, 0.992, 0.983, 0:01:21\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 2 epochs.\n",
    "\n",
    "Training Duration:  0:55:00\n",
    "\n",
    "Best Validation Accuracy:  0.996939556236\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_99.7_2017-01-25_12h55m34\n",
    "bend_right.png: Prediction: 30, Name: Beware of ice/snow\n",
    "\n",
    "do_not_enter.png: Prediction: 38, Name: Keep right\n",
    "\n",
    "german_do_not_enter.png: Prediction: 38, Name: Keep right\n",
    "\n",
    "german_priority.png: Prediction: 29, Name: Bicycles crossing\n",
    "\n",
    "keep_right.png: Prediction: 11, Name: Right-of-way at the next intersection\n",
    "\n",
    "no_passing.png: Prediction: 30, Name: Beware of ice/snow\n",
    "\n",
    "speed_limit.png: Prediction: 30, Name: Beware of ice/snow\n",
    "\n",
    "stop_sign.png: Prediction: 12, Name: Priority road\n",
    "\n",
    "uk_speed_limit_50.png: Prediction: 11, Name: Right-of-way at the next intersection\n",
    "\n",
    "yield.png: Prediction: 40, Name: Roundabout mandatory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout at end of each branch, wider fully-connected layers, min_accuracy=0.97\n",
    "\n",
    "Training... num_examples:  211728\n",
    "\n",
    "EPOCH, ValAcc, TrainSubsetAcc, Duration\n",
    "\n",
    "1, 0.755, 0.675, 0:01:25\n",
    "\n",
    "2, 0.885, 0.821, 0:01:25\n",
    "\n",
    "3, 0.946, 0.895, 0:01:25\n",
    "\n",
    "4, 0.970, 0.932, 0:01:25\n",
    "\n",
    "5, 0.972, 0.941, 0:01:25\n",
    "\n",
    "6, 0.983, 0.955, 0:01:25\n",
    "\n",
    "7, 0.981, 0.958, 0:01:25\n",
    "\n",
    "8, 0.984, 0.958, 0:01:25\n",
    "\n",
    "9, 0.985, 0.968, 0:01:25\n",
    "\n",
    "10, 0.986, 0.976, 0:01:25\n",
    "\n",
    "11, 0.988, 0.964, 0:01:25\n",
    "\n",
    "12, 0.991, 0.979, 0:01:25\n",
    "\n",
    "13, 0.989, 0.980, 0:01:25\n",
    "\n",
    "14, 0.991, 0.981, 0:01:25\n",
    "\n",
    "15, 0.990, 0.981, 0:01:25\n",
    "\n",
    "16, 0.991, 0.979, 0:01:25\n",
    "\n",
    "17, 0.990, 0.986, 0:01:25\n",
    "\n",
    "18, 0.995, 0.988, 0:01:25\n",
    "\n",
    "19, 0.994, 0.988, 0:01:25\n",
    "\n",
    "20, 0.991, 0.985, 0:01:25\n",
    "\n",
    "21, 0.992, 0.981, 0:01:25\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 2 epochs.\n",
    "\n",
    "Training Duration:  0:29:52\n",
    "\n",
    "Best Validation Accuracy:  0.994899260545\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_99.5_2017-01-25_02h17m53\n",
    "bend_right.png: Prediction: 9, Name: No passing\n",
    "\n",
    "do_not_enter.png: Prediction: 3, Name: Speed limit (60km/h)\n",
    "\n",
    "german_do_not_enter.png: Prediction: 17, Name: No entry\n",
    "\n",
    "german_priority.png: Prediction: 12, Name: Priority road\n",
    "\n",
    "keep_right.png: Prediction: 25, Name: Road work\n",
    "\n",
    "no_passing.png: Prediction: 18, Name: General caution\n",
    "\n",
    "speed_limit.png: Prediction: 25, Name: Road work\n",
    "\n",
    "stop_sign.png: Prediction: 17, Name: No entry\n",
    "\n",
    "uk_speed_limit_50.png: Prediction: 4, Name: Speed limit (70km/h)\n",
    "\n",
    "yield.png: Prediction: 9, Name: No passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform distribution of training examples (4000 per class)\n",
    "\n",
    "199, 0.948, 0.998, 0:00:47\n",
    "\n",
    "200, 0.947, 0.997, 0:00:47\n",
    "\n",
    "Training Duration:  2:37:51\n",
    "\n",
    "Best Validation Accuracy:  0.957153787755\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_95.7_2017-01-24_21h30m46\n",
    "bend_right.png: Prediction: 41, Name: End of no passing\n",
    "\n",
    "do_not_enter.png: Prediction: 34, Name: Turn left ahead\n",
    "\n",
    "german_do_not_enter.png: Prediction: 41, Name: End of no passing\n",
    "\n",
    "german_priority.png: Prediction: 39, Name: Keep left\n",
    "\n",
    "keep_right.png: Prediction: 41, Name: End of no passing\n",
    "\n",
    "no_passing.png: Prediction: 41, Name: End of no passing\n",
    "\n",
    "speed_limit.png: Prediction: 19, Name: Dangerous curve to the left\n",
    "\n",
    "stop_sign.png: Prediction: 41, Name: End of no passing\n",
    "\n",
    "uk_speed_limit_50.png: Prediction: 41, Name: End of no passing\n",
    "\n",
    "yield.png: Prediction: 39, Name: Keep left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32, 64, 128 depth conv filter branches\n",
    "\n",
    "Training... num_examples:  211728\n",
    "\n",
    "EPOCH, ValAcc, TrainSubsetAcc, Duration\n",
    "\n",
    "1, 0.951, 0.885, 0:01:19\n",
    "\n",
    "2, 0.970, 0.949, 0:01:18\n",
    "\n",
    "3, 0.985, 0.969, 0:01:18\n",
    "\n",
    "4, 0.994, 0.980, 0:01:17\n",
    "\n",
    "5, 0.994, 0.983, 0:01:17\n",
    "\n",
    "6, 0.996, 0.989, 0:01:18\n",
    "\n",
    "7, 0.994, 0.990, 0:01:17\n",
    "\n",
    "8, 0.995, 0.991, 0:01:17\n",
    "\n",
    "9, 0.988, 0.982, 0:01:17\n",
    "\n",
    "10, 0.996, 0.995, 0:01:24\n",
    "\n",
    "11, 0.996, 0.994, 0:01:17\n",
    "\n",
    "12, 0.993, 0.993, 0:01:17\n",
    "\n",
    "13, 0.994, 0.993, 0:01:17\n",
    "\n",
    "14, 0.991, 0.985, 0:01:17\n",
    "\n",
    "15, 0.990, 0.992, 0:01:17\n",
    "\n",
    "16, 0.996, 0.995, 0:01:17\n",
    "\n",
    "17, 0.996, 0.995, 0:01:17\n",
    "\n",
    "18, 0.996, 0.996, 0:01:17\n",
    "\n",
    "19, 0.996, 0.996, 0:01:17\n",
    "\n",
    "20, 0.995, 0.998, 0:01:17\n",
    "\n",
    "21, 0.997, 0.993, 0:01:17\n",
    "\n",
    "22, 0.996, 0.996, 0:01:17\n",
    "\n",
    "23, 0.996, 0.997, 0:01:17\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 2 epochs.\n",
    "\n",
    "Training Duration:  0:29:56\n",
    "\n",
    "Best Validation Accuracy:  0.997194593216\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_99.7_2017-01-24_15h30m50\n",
    "bend_right.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "do_not_enter.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "german_do_not_enter.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "german_priority.png: Prediction: 4, Name: Speed limit (70km/h)\n",
    "\n",
    "keep_right.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "no_passing.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "speed_limit.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "stop_sign.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "uk_speed_limit_50.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "yield.png: Prediction: 5, Name: Speed limit (80km/h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdamOptimizer and Predictions\n",
    "\n",
    "Training... num_examples:  211728\n",
    "\n",
    "EPOCH, ValAcc, TrainSubsetAcc, Duration\n",
    "\n",
    "1, 0.955, 0.908, 0:00:58\n",
    "\n",
    "2, 0.985, 0.966, 0:00:57\n",
    "\n",
    "3, 0.990, 0.974, 0:00:57\n",
    "\n",
    "4, 0.988, 0.981, 0:00:57\n",
    "\n",
    "5, 0.994, 0.988, 0:00:57\n",
    "\n",
    "6, 0.992, 0.986, 0:00:57\n",
    "\n",
    "7, 0.995, 0.994, 0:00:57\n",
    "\n",
    "8, 0.996, 0.995, 0:00:57\n",
    "\n",
    "9, 0.996, 0.996, 0:00:57\n",
    "\n",
    "10, 0.992, 0.993, 0:00:57\n",
    "\n",
    "11, 0.996, 0.996, 0:00:57\n",
    "\n",
    "12, 0.994, 0.995, 0:00:57\n",
    "\n",
    "13, 0.998, 0.997, 0:00:57\n",
    "\n",
    "14, 0.996, 0.995, 0:00:57\n",
    "\n",
    "15, 0.997, 0.997, 0:00:57\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 2 epochs.\n",
    "\n",
    "Training Duration:  0:14:24\n",
    "\n",
    "Best Validation Accuracy:  0.997959704157\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_99.8_2017-01-23_13h38m23\n",
    "\n",
    "bend_right.png: Prediction: 17, Name: b'Vehicles over 3.5 metric tons prohibited'\n",
    "\n",
    "do_not_enter.png: Prediction: 17, Name: b'Vehicles over 3.5 metric tons prohibited'\n",
    "\n",
    "speed_limit.png: Prediction: 3, Name: b'Speed limit (50km/h)'\n",
    "\n",
    "stop_sign.png: Prediction: 17, Name: b'Vehicles over 3.5 metric tons prohibited'\n",
    "\n",
    "yield.png: Prediction: 17, Name: b'Vehicles over 3.5 metric tons prohibited'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdamOptimizer and Final Model\n",
    "\n",
    "Training... num_examples:  211728\n",
    "\n",
    "EPOCH, ValAcc, TrainSubsetAcc, Duration\n",
    "\n",
    "1, 0.956, 0.908, 0:00:56\n",
    "\n",
    "2, 0.987, 0.961, 0:00:57\n",
    "\n",
    "3, 0.985, 0.965, 0:01:00\n",
    "\n",
    "4, 0.992, 0.978, 0:01:00\n",
    "\n",
    "5, 0.993, 0.982, 0:00:59\n",
    "\n",
    "6, 0.994, 0.991, 0:00:59\n",
    "\n",
    "7, 0.993, 0.990, 0:00:59\n",
    "\n",
    "8, 0.993, 0.991, 0:01:00\n",
    "\n",
    "9, 0.995, 0.994, 0:01:00\n",
    "\n",
    "10, 0.995, 0.989, 0:00:59\n",
    "\n",
    "11, 0.997, 0.996, 0:00:59\n",
    "\n",
    "12, 0.995, 0.993, 0:00:59\n",
    "\n",
    "13, 0.995, 0.992, 0:00:59\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 2 epochs.\n",
    "\n",
    "Training Duration:  0:12:53\n",
    "\n",
    "Best Validation Accuracy:  0.997194593216\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_99.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdagradOptimizer\n",
    "\n",
    "191, 0.970, 0.923, 0:00:57\n",
    "\n",
    "192, 0.968, 0.925, 0:00:57\n",
    "\n",
    "193, 0.968, 0.923, 0:00:57\n",
    "\n",
    "194, 0.968, 0.928, 0:00:57\n",
    "\n",
    "195, 0.969, 0.921, 0:00:57\n",
    "\n",
    "196, 0.969, 0.928, 0:00:57\n",
    "\n",
    "197, 0.968, 0.935, 0:00:57\n",
    "\n",
    "198, 0.970, 0.920, 0:00:57\n",
    "\n",
    "199, 0.969, 0.920, 0:00:57\n",
    "\n",
    "200, 0.963, 0.924, 0:00:57\n",
    "\n",
    "Training Duration:  3:12:22\n",
    "\n",
    "Best Validation Accuracy:  0.970160673906\n",
    "\n",
    "Model saved:  .\\cnn_branch_pyramid_97.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientDescentOptimizer\n",
    "\n",
    "Training... num_examples:  211728\n",
    "\n",
    "EPOCH, ValAcc, TrainSubsetAcc\n",
    "\n",
    "1, 0.052, 0.057\n",
    "\n",
    "2, 0.052, 0.063\n",
    "\n",
    "3, 0.052, 0.059\n",
    "\n",
    "4, 0.052, 0.066\n",
    "\n",
    "5, 0.052, 0.060\n",
    "\n",
    "6, 0.052, 0.061\n",
    "\n",
    "7, 0.052, 0.059\n",
    "\n",
    "8, 0.052, 0.058\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 7 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (All runs below use AdamOptimizer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 epochs and early-stopping\n",
    "\n",
    "Training... num_examples:  211728\n",
    "\n",
    "EPOCH, ValAcc, TrainSubsetAcc\n",
    "\n",
    "1, 0.963, 0.902\n",
    "\n",
    "2, 0.989, 0.963\n",
    "\n",
    "3, 0.990, 0.972\n",
    "\n",
    "4, 0.989, 0.979\n",
    "\n",
    "5, 0.995, 0.983\n",
    "\n",
    "6, 0.992, 0.983\n",
    "\n",
    "7, 0.995, 0.991\n",
    "\n",
    "8, 0.995, 0.994\n",
    "\n",
    "9, 0.995, 0.990\n",
    "\n",
    "10, 0.994, 0.992\n",
    "\n",
    "11, 0.997, 0.998\n",
    "\n",
    "12, 0.996, 0.995\n",
    "\n",
    "13, 0.993, 0.994\n",
    "\n",
    "14, 0.997, 0.996\n",
    "\n",
    "15, 0.996, 0.994\n",
    "\n",
    "16, 0.995, 0.995\n",
    "\n",
    "17, 0.997, 0.996\n",
    "\n",
    "18, 0.996, 0.997\n",
    "\n",
    "Stopping early. Validation accuracy has not improved in 7 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 Epochs\n",
    "\n",
    "num_examples:  211728\n",
    "\n",
    "Training...\n",
    "\n",
    "EPOCH, ValAcc, ValLoss, TrainSAcc, TrainSLoss\n",
    "\n",
    "1, 0.887, 0.358, 0.830, 0.537\n",
    "\n",
    "2, 0.969, 0.118, 0.947, 0.176\n",
    "\n",
    "3, 0.983, 0.058, 0.975, 0.080\n",
    "\n",
    "4, 0.986, 0.070, 0.978, 0.066\n",
    "\n",
    "5, 0.994, 0.036, 0.986, 0.049\n",
    "\n",
    "6, 0.986, 0.079, 0.978, 0.086\n",
    "\n",
    "7, 0.993, 0.045, 0.992, 0.032\n",
    "\n",
    "8, 0.995, 0.023, 0.992, 0.025\n",
    "\n",
    "9, 0.992, 0.038, 0.993, 0.025\n",
    "\n",
    "10, 0.994, 0.035, 0.991, 0.033\n",
    "\n",
    "11, 0.995, 0.029, 0.996, 0.026\n",
    "\n",
    "12, 0.992, 0.030, 0.988, 0.044\n",
    "\n",
    "13, 0.993, 0.032, 0.995, 0.019\n",
    "\n",
    "14, 0.997, 0.016, 0.995, 0.024\n",
    "\n",
    "15, 0.997, 0.017, 0.994, 0.028\n",
    "\n",
    "16, 0.998, 0.016, 0.996, 0.012\n",
    "\n",
    "17, 0.996, 0.039, 0.994, 0.020\n",
    "\n",
    "18, 0.996, 0.027, 0.998, 0.005\n",
    "\n",
    "19, 0.998, 0.014, 0.997, 0.010\n",
    "\n",
    "20, 0.998, 0.016, 0.997, 0.013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and validation after generating extra data:\n",
    "num_examples:  211728\n",
    "Training...\n",
    "\n",
    "EPOCH 1 ...\n",
    "Validation Accuracy = 0.878\n",
    "\n",
    "EPOCH 2 ...\n",
    "Validation Accuracy = 0.942\n",
    "\n",
    "EPOCH 3 ...\n",
    "Validation Accuracy = 0.954\n",
    "\n",
    "EPOCH 4 ...\n",
    "Validation Accuracy = 0.956\n",
    "\n",
    "EPOCH 5 ...\n",
    "Validation Accuracy = 0.975\n",
    "\n",
    "EPOCH 6 ...\n",
    "Validation Accuracy = 0.978\n",
    "\n",
    "EPOCH 7 ...\n",
    "Validation Accuracy = 0.970\n",
    "\n",
    "EPOCH 8 ...\n",
    "Validation Accuracy = 0.975\n",
    "\n",
    "EPOCH 9 ...\n",
    "Validation Accuracy = 0.981\n",
    "\n",
    "EPOCH 10 ...\n",
    "Validation Accuracy = 0.978"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train and validation before generating extra data\n",
    "num_examples:  211728\n",
    "Training...\n",
    "\n",
    "EPOCH 1 ...\n",
    "Validation Accuracy = 0.978\n",
    "\n",
    "EPOCH 2 ...\n",
    "Validation Accuracy = 0.986\n",
    "\n",
    "EPOCH 3 ...\n",
    "Validation Accuracy = 0.995\n",
    "\n",
    "EPOCH 4 ...\n",
    "Validation Accuracy = 0.993\n",
    "\n",
    "EPOCH 5 ...\n",
    "Validation Accuracy = 0.995\n",
    "\n",
    "EPOCH 6 ...\n",
    "Validation Accuracy = 0.994\n",
    "\n",
    "EPOCH 7 ...\n",
    "Validation Accuracy = 0.998\n",
    "\n",
    "EPOCH 8 ...\n",
    "Validation Accuracy = 0.993\n",
    "\n",
    "EPOCH 9 ...\n",
    "Validation Accuracy = 0.995\n",
    "\n",
    "EPOCH 10 ...\n",
    "Validation Accuracy = 0.993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    if train_model:\n",
    "        model = model_filename\n",
    "    else:\n",
    "        #model = '.\\\\cnn_branch_pyramid_99.8_2017-01-23_13h38m23'\n",
    "        #model = '.\\\\cnn_branch_pyramid_99.7_2017-01-24_15h30m50'\n",
    "        model = '.\\\\cnn_branch_pyramid_99.7_2017-01-25_23h20m01'\n",
    "    \n",
    "    # http://stackoverflow.com/questions/33759623/tensorflow-how-to-restore-a-previously-saved-model-python\n",
    "    saver = tf.train.import_meta_graph(model + '.meta')\n",
    "    saver.restore(sess, model)\n",
    "    \n",
    "    print('Restored model: ', model)\n",
    "    \n",
    "    evaluate_test_accuracy(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restored model:  .\\cnn_branch_pyramid_99.8_2017-01-26_16h58m44\n",
    "Test Set Size:  12630\n",
    "Test Accuracy: 0.9827\n",
    "Duration: 0:00:03\n",
    "\n",
    "Restored model:  .\\cnn_branch_pyramid_99.6_2017-01-26_14h53m51\n",
    "Test Set Size:  12630\n",
    "Test Accuracy: 0.9805\n",
    "Duration: 0:00:03\n",
    "\n",
    "Restored model:  .\\cnn_branch_pyramid_99.7_2017-01-26_02h35m23\n",
    "Test Set Size:  12630\n",
    "Test Accuracy: 0.9787\n",
    "Duration: 0:00:04\n",
    "\n",
    "Restored model:  .\\cnn_branch_pyramid_99.5_2017-01-26_00h57m57\n",
    "Test Set Size:  12630\n",
    "Test Accuracy: 0.9761\n",
    "Duration: 0:00:04\n",
    "\n",
    "Restored model:  .\\cnn_branch_pyramid_99.7_2017-01-25_23h20m01\n",
    "Test Set Size:  12630\n",
    "Test Accuracy: 0.9669\n",
    "Duration: 0:00:01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "_How did you train your model? (Type of optimizer, batch size, epochs, hyperparameters, etc.)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "I trained my model with AdamOptimizer and these hyperparameters:\n",
    "- Batch size: 128\n",
    "- Epochs (with early stopping): 200\n",
    "- Dropout: 0.4\n",
    "- Learning rate: 0.0001\n",
    "- Number of jittered images per training example: 10\n",
    "- (mu, sigma) for weight initialization: (0, 0.1)\n",
    "- Epochs since improvement for early stop: 2\n",
    "\n",
    "I tried other optimizers but compared to AdamOptimizer, some were slower to reach the highest accuracy and others reached a lower validation accuracy.\n",
    "\n",
    "Early-stopping usually kicked in during training. In my final training run, it stopped after 17 epochs.\n",
    "\n",
    "I tried lower dropouts like 0.2, but when I did that, the training seemed to be stuck at a low validation accuracy (like 5%).\n",
    "\n",
    "I tried learning rates of 0.001 and 0.0001 and achieved a slightly improved validation accuracy with the smaller learning rate.\n",
    "\n",
    "I tried different approaches for generating jittered images. \n",
    "1. Scale up the count of training examples by some factor, thereby keeping the above non-uniform distribution.\n",
    "2. Increase the count of training examples to cause a uniform distribution of classes.\n",
    "\n",
    "The first approach resulted in better validation accuracy, likely because the distribution of labels was closer between the training set and validation set.\n",
    "\n",
    "I did not try different values of (mu, sigma) for weight initialization.\n",
    "\n",
    "I tried larger values for \"epochs since improvement for early stop\" but I realized that could risk overfitting, so I lowered to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "\n",
    "_What approach did you take in coming up with a solution to this problem? It may have been a process of trial and error, in which case, outline the steps you took to get to the final solution and why you chose those steps. Perhaps your solution involved an already well known implementation or architecture. In this case, discuss why you think this is suitable for the current problem._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Test a Model on New Images\n",
    "\n",
    "Take several pictures of traffic signs that you find on the web or around you (at least five), and run them through your classifier on your computer to produce example results. The classifier might not recognize some local signs but it could prove interesting nonetheless.\n",
    "\n",
    "You may find `signnames.csv` useful as it contains mappings from the class id (integer) to the actual sign name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fignum = 0\n",
    "\n",
    "for file in test_files:\n",
    "    img = mpimg.imread('.\\\\test_images\\\\' + file)\n",
    "    fignum += 1\n",
    "    draw_image(img, file, fignum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "_Choose five candidate images of traffic signs and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult? It could be helpful to plot the images in the notebook._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Run the predictions here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if train_model:\n",
    "        model = model_filename\n",
    "    else:\n",
    "        model = '.\\\\cnn_branch_pyramid_99.8_2017-01-23_13h38m23'\n",
    "    \n",
    "    # http://stackoverflow.com/questions/33759623/tensorflow-how-to-restore-a-previously-saved-model-python\n",
    "    saver = tf.train.import_meta_graph(model + '.meta')\n",
    "    saver.restore(sess, model)\n",
    "    predict_test_images(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "\n",
    "bend_right.png: Prediction: 17, Name: No entry\n",
    "\n",
    "do_not_enter.png: Prediction: 17, Name: No entry\n",
    "\n",
    "german_do_not_enter.png: Prediction: 17, Name: No entry\n",
    "\n",
    "german_priority.png: Prediction: 17, Name: No entry\n",
    "\n",
    "keep_right.png: Prediction: 3, Name: Speed limit (60km/h)\n",
    "\n",
    "no_passing.png: Prediction: 10, Name: No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "speed_limit.png: Prediction: 3, Name: Speed limit (60km/h)\n",
    "\n",
    "stop_sign.png: Prediction: 17, Name: No entry\n",
    "\n",
    "uk_speed_limit_50.png: Prediction: 5, Name: Speed limit (80km/h)\n",
    "\n",
    "yield.png: Prediction: 17, Name: No entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "_Is your model able to perform equally well on captured pictures when compared to testing on the dataset? The simplest way to do this check the accuracy of the predictions. For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate._\n",
    "\n",
    "_**NOTE:** You could check the accuracy manually by using `signnames.csv` (same directory). This file has a mapping from the class id (0-42) to the corresponding sign name. So, you could take the class id the model outputs, lookup the name in `signnames.csv` and see if it matches the sign from the image._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Visualize the softmax probabilities here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "def certainty(sess, X_pred):\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    softmax_output = sess.run(softmax, feed_dict={x: X_pred, kp: 1.0})\n",
    "    top_k = tf.nn.top_k(tf.constant(softmax_output), k=5)\n",
    "    top_k_output = sess.run(top_k)\n",
    "    return top_k_output\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def eval_certainty(sess):\n",
    "    X = read_test_images()\n",
    "    \n",
    "    top_k = certainty(sess, X)\n",
    "    \n",
    "    for i in range(len(test_files)):\n",
    "        print('### ' + test_files[i])\n",
    "        print()\n",
    "        for j in range(len(top_k.values[i])):\n",
    "            id_pred = top_k.indices[i][j]\n",
    "            print('{:.3f}, {}, {}'.format(top_k.values[i][j], top_k.indices[i][j], signname_map[id_pred]))\n",
    "            print()\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    if train_model:\n",
    "        model = model_filename\n",
    "    else:\n",
    "        model = '.\\\\cnn_branch_pyramid_99.8_2017-01-23_13h38m23'\n",
    "    \n",
    "    # http://stackoverflow.com/questions/33759623/tensorflow-how-to-restore-a-previously-saved-model-python\n",
    "    saver = tf.train.import_meta_graph(model + '.meta')\n",
    "    saver.restore(sess, model)\n",
    "    eval_certainty(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy 98.27%\n",
    "\n",
    "model = .\\cnn_branch_pyramid_99.8_2017-01-26_16h58m44\n",
    "\n",
    "### bend_right.png\n",
    "\n",
    "0.075, 5, Speed limit (80km/h)\n",
    "\n",
    "0.073, 8, Speed limit (120km/h)\n",
    "\n",
    "0.056, 31, Wild animals crossing\n",
    "\n",
    "0.051, 7, Speed limit (100km/h)\n",
    "\n",
    "0.050, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "### do_not_enter.png\n",
    "\n",
    "0.080, 5, Speed limit (80km/h)\n",
    "\n",
    "0.075, 8, Speed limit (120km/h)\n",
    "\n",
    "0.071, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "0.058, 31, Wild animals crossing\n",
    "\n",
    "0.057, 7, Speed limit (100km/h)\n",
    "\n",
    "### german_do_not_enter.png\n",
    "\n",
    "0.084, 5, Speed limit (80km/h)\n",
    "\n",
    "0.074, 8, Speed limit (120km/h)\n",
    "\n",
    "0.069, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "0.059, 7, Speed limit (100km/h)\n",
    "\n",
    "0.053, 31, Wild animals crossing\n",
    "\n",
    "### german_priority.png\n",
    "\n",
    "0.077, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "0.067, 5, Speed limit (80km/h)\n",
    "\n",
    "0.062, 8, Speed limit (120km/h)\n",
    "\n",
    "0.057, 31, Wild animals crossing\n",
    "\n",
    "0.053, 7, Speed limit (100km/h)\n",
    "\n",
    "### keep_right.png\n",
    "\n",
    "0.065, 5, Speed limit (80km/h)\n",
    "\n",
    "0.047, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "0.046, 8, Speed limit (120km/h)\n",
    "\n",
    "0.044, 38, Keep right\n",
    "\n",
    "0.044, 4, Speed limit (70km/h)\n",
    "\n",
    "### no_passing.png\n",
    "\n",
    "0.082, 5, Speed limit (80km/h)\n",
    "\n",
    "0.073, 8, Speed limit (120km/h)\n",
    "\n",
    "0.069, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "0.053, 7, Speed limit (100km/h)\n",
    "\n",
    "0.046, 9, No passing\n",
    "\n",
    "### speed_limit.png\n",
    "\n",
    "0.082, 5, Speed limit (80km/h)\n",
    "\n",
    "0.067, 8, Speed limit (120km/h)\n",
    "\n",
    "0.057, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "0.053, 7, Speed limit (100km/h)\n",
    "\n",
    "0.046, 4, Speed limit (70km/h)\n",
    "\n",
    "### stop_sign.png\n",
    "\n",
    "0.080, 8, Speed limit (120km/h)\n",
    "\n",
    "0.076, 5, Speed limit (80km/h)\n",
    "\n",
    "0.069, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "0.058, 7, Speed limit (100km/h)\n",
    "\n",
    "0.057, 31, Wild animals crossing\n",
    "\n",
    "### uk_speed_limit_50.png\n",
    "\n",
    "0.083, 5, Speed limit (80km/h)\n",
    "\n",
    "0.055, 8, Speed limit (120km/h)\n",
    "\n",
    "0.052, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "0.046, 7, Speed limit (100km/h)\n",
    "\n",
    "0.045, 4, Speed limit (70km/h)\n",
    "\n",
    "### yield.png\n",
    "\n",
    "0.084, 5, Speed limit (80km/h)\n",
    "\n",
    "0.067, 8, Speed limit (120km/h)\n",
    "\n",
    "0.059, 7, Speed limit (100km/h)\n",
    "\n",
    "0.057, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "0.046, 4, Speed limit (70km/h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bend_right.png\n",
    "\n",
    "0.583, 17, No entry\n",
    "\n",
    "0.149, 3, Speed limit (60km/h)\n",
    "\n",
    "0.094, 5, Speed limit (80km/h)\n",
    "\n",
    "0.031, 9, No passing\n",
    "\n",
    "0.027, 30, Beware of ice/snow\n",
    "\n",
    "### do_not_enter.png\n",
    "\n",
    "0.572, 17, No entry\n",
    "\n",
    "0.112, 3, Speed limit (60km/h)\n",
    "\n",
    "0.077, 7, Speed limit (100km/h)\n",
    "\n",
    "0.048, 5, Speed limit (80km/h)\n",
    "\n",
    "0.041, 30, Beware of ice/snow\n",
    "\n",
    "### german_do_not_enter.png\n",
    "\n",
    "0.617, 17, No entry\n",
    "\n",
    "0.090, 30, Beware of ice/snow\n",
    "\n",
    "0.074, 3, Speed limit (60km/h)\n",
    "\n",
    "0.035, 7, Speed limit (100km/h)\n",
    "\n",
    "0.028, 9, No passing\n",
    "\n",
    "### german_priority.png\n",
    "\n",
    "0.342, 17, No entry\n",
    "\n",
    "0.152, 30, Beware of ice/snow\n",
    "\n",
    "0.113, 5, Speed limit (80km/h)\n",
    "\n",
    "0.100, 3, Speed limit (60km/h)\n",
    "\n",
    "0.085, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "### keep_right.png\n",
    "\n",
    "0.273, 3, Speed limit (60km/h)\n",
    "\n",
    "0.201, 5, Speed limit (80km/h)\n",
    "\n",
    "0.172, 30, Beware of ice/snow\n",
    "\n",
    "0.081, 38, Keep right\n",
    "\n",
    "0.051, 17, No entry\n",
    "\n",
    "### no_passing.png\n",
    "\n",
    "0.238, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "0.192, 5, Speed limit (80km/h)\n",
    "\n",
    "0.107, 3, Speed limit (60km/h)\n",
    "\n",
    "0.086, 9, No passing\n",
    "\n",
    "0.085, 17, No entry\n",
    "\n",
    "### speed_limit.png\n",
    "\n",
    "0.275, 3, Speed limit (60km/h)\n",
    "\n",
    "0.220, 5, Speed limit (80km/h)\n",
    "\n",
    "0.132, 17, No entry\n",
    "\n",
    "0.130, 30, Beware of ice/snow\n",
    "\n",
    "0.050, 7, Speed limit (100km/h)\n",
    "\n",
    "### stop_sign.png\n",
    "\n",
    "0.431, 17, No entry\n",
    "\n",
    "0.106, 3, Speed limit (60km/h)\n",
    "\n",
    "0.078, 30, Beware of ice/snow\n",
    "\n",
    "0.059, 5, Speed limit (80km/h)\n",
    "\n",
    "0.036, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "### uk_speed_limit_50.png\n",
    "\n",
    "0.194, 5, Speed limit (80km/h)\n",
    "\n",
    "0.190, 3, Speed limit (60km/h)\n",
    "\n",
    "0.172, 17, No entry\n",
    "\n",
    "0.085, 30, Beware of ice/snow\n",
    "\n",
    "0.062, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "### yield.png\n",
    "\n",
    "0.630, 17, No entry\n",
    "\n",
    "0.087, 5, Speed limit (80km/h)\n",
    "\n",
    "0.069, 3, Speed limit (60km/h)\n",
    "\n",
    "0.049, 10, No passing for vehicles over 3.5 metric tons\n",
    "\n",
    "0.030, 30, Beware of ice/snow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "*Use the model's softmax probabilities to visualize the **certainty** of its predictions, [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#top_k) could prove helpful here. Which predictions is the model certain of? Uncertain? If the model was incorrect in its initial prediction, does the correct prediction appear in the top k? (k should be 5 at most)*\n",
    "\n",
    "`tf.nn.top_k` will return the values and indices (class ids) of the top k predictions. So if k=3, for each sign, it'll return the 3 largest probabilities (out of a possible 43) and the correspoding class ids.\n",
    "\n",
    "Take this numpy array as an example:\n",
    "\n",
    "```\n",
    "# (5, 6) array\n",
    "a = np.array([[ 0.24879643,  0.07032244,  0.12641572,  0.34763842,  0.07893497,\n",
    "         0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.08594638,  0.0178669 ,  0.18063401,\n",
    "         0.15899337],\n",
    "       [ 0.26076848,  0.23664738,  0.08020603,  0.07001922,  0.1134371 ,\n",
    "         0.23892179],\n",
    "       [ 0.11943333,  0.29198961,  0.02605103,  0.26234032,  0.1351348 ,\n",
    "         0.16505091],\n",
    "       [ 0.09561176,  0.34396535,  0.0643941 ,  0.16240774,  0.24206137,\n",
    "         0.09155967]])\n",
    "```\n",
    "\n",
    "Running it through `sess.run(tf.nn.top_k(tf.constant(a), k=3))` produces:\n",
    "\n",
    "```\n",
    "TopKV2(values=array([[ 0.34763842,  0.24879643,  0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.18063401],\n",
    "       [ 0.26076848,  0.23892179,  0.23664738],\n",
    "       [ 0.29198961,  0.26234032,  0.16505091],\n",
    "       [ 0.34396535,  0.24206137,  0.16240774]]), indices=array([[3, 0, 5],\n",
    "       [0, 1, 4],\n",
    "       [0, 5, 1],\n",
    "       [1, 3, 5],\n",
    "       [1, 4, 3]], dtype=int32))\n",
    "```\n",
    "\n",
    "Looking just at the first row we get `[ 0.34763842,  0.24879643,  0.12789202]`, you can confirm these are the 3 largest probabilities in `a`. You'll also notice `[3, 0, 5]` are the corresponding indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
